from bs4 import BeautifulSoup
from time import sleep
import requests 

i = 0
while(True):
    try:
        if i == 0:
            url = "http://www.creationdentreprise.sn/rechercher-une-societe?field_rc_societe_value=&amp;field_ninea_societe_value=&amp;denomination=&amp;field_localite_nid=All&amp;field_siege_societe_value=&amp;field_forme_juriduqe_nid=All&amp;field_secteur_nid=All&amp;field_date_crea_societe_value=&amp;page="
        else:
            url = "http://www.creationdentreprise.sn/rechercher-une-societe?field_rc_societe_value=&amp;field_ninea_societe_value=&amp;denomination=&amp;field_localite_nid=All&amp;field_siege_societe_value=&amp;field_forme_juriduqe_nid=All&amp;field_secteur_nid=All&amp;field_date_crea_societe_value=&amp;page={}".format(i)
        r = requests.get(url)
        soup = BeautifulSoup(r.content, 'html.parser')

        
        # Open the text file. Use with to save self from grief.
        with open('results.txt','a') as acct:
            for url_ in url:
                print("Processing {}...".format(url_))
                r_new = requests.get(url_)
                soup_new = BeautifulSoup(r_new.text)
                for tr in soup_new.find_all('tr', align='center'):
                    stack = []
                    for td in tr.findAll('td'):
                        stack.append(td.text.replace('\n', '').replace('\t', '').strip())
                    acct.write(", ".join(stack) + '\n')

        #don't overflow website
        sleep(2)

        #increase page number
        i += 1
    except:
        break
